  
  * custom serialization functions for lists of 'WordX's
      - use benchmarks to determine best chunk size
      - benchmark chunk size speedup for more complicated computations of list
        elements => to be expected that we get no speedup anymore or even a
        slowdown => adapt Text.Blaze.Builder.Word accordingly.

  * fast serialization for 'Text' values (currently unpacking to 'String' is
    the fastest :-/)

  * implement further encodings for 'Char'

  * implement end-of-buffer wrapping when copying bytestrings

  * extend tests to new functions

  * benchmarks
      - understand why the declarative blaze-builder version is the fastest
        serializer for Word64 little-endian and big-endian 
      - check the cost of using `mappend` on builders instead of writes.
      - show that using toByteStringIO has an advantage over toLazyByteString

  * documentation

  * check portability to Hugs

  * performance:
      - perhaps we could improve performance by taking page size, page
        alignment, and memory access alignment into account.

      - detect machine endianness and use host order writes for the supported
        endianness.

  * testing
      - port tests from 'Data.Binary.Builder' to ensure that the word writes
        and builders are working correctly. I may have missed some pitfalls
        about word types in Haskell during porting the functions from
        'Data.Binary.Builder'.

  * portability
      - port to Hugs
      - test lower versions of GHC
